{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 30027,
     "status": "ok",
     "timestamp": 1736752580629,
     "user": {
      "displayName": "Carol",
      "userId": "14860603171832092381"
     },
     "user_tz": -480
    },
    "id": "rvBCXmt9StxU",
    "outputId": "278d6032-bfd3-4b49-cb4b-a9cf0f349b57"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1736752580629,
     "user": {
      "displayName": "Carol",
      "userId": "14860603171832092381"
     },
     "user_tz": -480
    },
    "id": "g39eDORZTdAN",
    "outputId": "41a8e702-4630-466f-8c47-e01ab8903b34"
   },
   "outputs": [],
   "source": [
    "# 查看挂载目录内容\n",
    "!ls /content/drive/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "74_NbzsHS6dw"
   },
   "source": [
    "加载数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 819209,
     "status": "ok",
     "timestamp": 1736753406869,
     "user": {
      "displayName": "Carol",
      "userId": "14860603171832092381"
     },
     "user_tz": -480
    },
    "id": "hR3pmKJvS8CL",
    "outputId": "41a41e88-4fe2-4347-8a3b-e09e88decb56"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# 创建目录\n",
    "os.makedirs('/content/coco', exist_ok=True)\n",
    "\n",
    "# 下载 COCO 数据集的训练图像\n",
    "!wget -c http://images.cocodataset.org/zips/train2017.zip -P /content/coco/\n",
    "!unzip -q /content/coco/train2017.zip -d /content/coco/\n",
    "\n",
    "# 下载 COCO 数据集的验证图像\n",
    "!wget -c http://images.cocodataset.org/zips/val2017.zip -P /content/coco/\n",
    "!unzip -q /content/coco/val2017.zip -d /content/coco/\n",
    "\n",
    "# 下载 COCO 的标注文件\n",
    "!wget -c http://images.cocodataset.org/annotations/annotations_trainval2017.zip -P /content/coco/\n",
    "!unzip -q /content/coco/annotations_trainval2017.zip -d /content/coco/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 993,
     "status": "ok",
     "timestamp": 1736753407858,
     "user": {
      "displayName": "Carol",
      "userId": "14860603171832092381"
     },
     "user_tz": -480
    },
    "id": "iTdBv828V284",
    "outputId": "48012912-65df-409b-d337-5b24e0111216"
   },
   "outputs": [],
   "source": [
    "!ls /content/coco\n",
    "!rm /content/coco/*.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YlJ-kOCZWHKx"
   },
   "source": [
    "导入必要的包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kKCNjZNqWI0g"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torchvision\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import CocoDetection\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BAo63ptiWNGW"
   },
   "source": [
    "配置参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1736761991554,
     "user": {
      "displayName": "Carol",
      "userId": "14860603171832092381"
     },
     "user_tz": -480
    },
    "id": "W7hqdbeqWPsh",
    "outputId": "9ee216a0-78a2-4214-b978-cba9664f05b6"
   },
   "outputs": [],
   "source": [
    "content_layers = [22]\n",
    "style_layers = [1, 6, 11, 20, 29]\n",
    "\n",
    "content_weight = 2e9\n",
    "style_weight = 6e3\n",
    "\n",
    "root_dir = \"/content/coco/train2017\"\n",
    "annFile = \"/content/coco/annotations/instances_train2017.json\"\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "style_image_path = \"/content/drive/MyDrive/starry_night.jpg\"\n",
    "\n",
    "batch_size = 24\n",
    "learning_rate = 1e-4\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4U6T4evOjO3a"
   },
   "source": [
    "## 生成模型定义\n",
    "\n",
    "降采样"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w0WILB1DjSWx"
   },
   "outputs": [],
   "source": [
    "class DownSample(nn.Module):\n",
    "    \"\"\"下采样层\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride):\n",
    "        super().__init__()\n",
    "        self.padding = nn.ReflectionPad2d(kernel_size // 2)\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size, stride)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"前向传播\"\"\"\n",
    "        return self.conv(self.padding(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1KHx-txjjUSf"
   },
   "source": [
    "残差块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wlbveSrNjV3i"
   },
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    \"\"\"残差块\"\"\"\n",
    "\n",
    "    def __init__(self, channels):\n",
    "        super().__init__()\n",
    "        self.padding1 = nn.ReflectionPad2d(1)\n",
    "        self.conv1 = nn.Conv2d(channels, channels, 3, 1)\n",
    "        self.in1 = nn.InstanceNorm2d(channels, affine=True)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.padding2 = nn.ReflectionPad2d(1)\n",
    "        self.conv2 = nn.Conv2d(channels, channels, 3, 1)\n",
    "        self.in2 = nn.InstanceNorm2d(channels, affine=True)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"前向传播\"\"\"\n",
    "        residual = x\n",
    "        out = self.relu(self.in1(self.conv1(self.padding1(x))))\n",
    "        out = self.in2(self.conv2(self.padding2(out)))\n",
    "        out = out + residual\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BEz92RGIjaXS"
   },
   "source": [
    "升采样"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JdXYQBVljdMr"
   },
   "outputs": [],
   "source": [
    "class UpSample(nn.Module):\n",
    "    \"\"\"上采样层\"\"\"\n",
    "\n",
    "    # pylint: disable=too-many-arguments, too-many-positional-arguments\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride, upsample=None):\n",
    "        super().__init__()\n",
    "        self.upsample = upsample\n",
    "        self.padding = nn.ReflectionPad2d(kernel_size // 2)\n",
    "        self.conv2d = nn.Conv2d(in_channels, out_channels, kernel_size, stride)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"前向传播\"\"\"\n",
    "        x_in = x\n",
    "        if self.upsample:\n",
    "            x_in = torch.nn.functional.interpolate(\n",
    "                x_in, mode=\"nearest\", scale_factor=self.upsample\n",
    "            )\n",
    "        return self.conv2d(self.padding(x_in))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2-_jzTgFje-a"
   },
   "source": [
    "模型定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "09hQ4Yb2jhPB"
   },
   "outputs": [],
   "source": [
    "class TransferNet(nn.Module):\n",
    "    \"\"\"风格迁移网络\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.downsample1 = DownSample(3, 32, 9, 1)\n",
    "        self.in1 = nn.InstanceNorm2d(32, affine=True)\n",
    "        self.downsample2 = DownSample(32, 64, 3, 2)\n",
    "        self.in2 = nn.InstanceNorm2d(64, affine=True)\n",
    "        self.downsample3 = DownSample(64, 128, 3, 2)\n",
    "        self.in3 = nn.InstanceNorm2d(128, affine=True)\n",
    "        self.residual1 = ResidualBlock(128)\n",
    "        self.residual2 = ResidualBlock(128)\n",
    "        self.residual3 = ResidualBlock(128)\n",
    "        self.residual4 = ResidualBlock(128)\n",
    "        self.residual5 = ResidualBlock(128)\n",
    "        self.upsample1 = UpSample(128, 64, 3, 1, 2)\n",
    "        self.in4 = nn.InstanceNorm2d(64, affine=True)\n",
    "        self.upsample2 = UpSample(64, 32, 3, 1, 2)\n",
    "        self.in5 = nn.InstanceNorm2d(32, affine=True)\n",
    "        self.upsample3 = DownSample(32, 3, 9, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"前向传播\"\"\"\n",
    "        out = self.relu(self.in1(self.downsample1(x)))\n",
    "        out = self.relu(self.in2(self.downsample2(out)))\n",
    "        out = self.relu(self.in3(self.downsample3(out)))\n",
    "        out = self.residual1(out)\n",
    "        out = self.residual2(out)\n",
    "        out = self.residual3(out)\n",
    "        out = self.residual4(out)\n",
    "        out = self.residual5(out)\n",
    "        out = self.relu(self.in4(self.upsample1(out)))\n",
    "        out = self.relu(self.in5(self.upsample2(out)))\n",
    "        out = self.upsample3(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e3YS7tmZjjE5"
   },
   "source": [
    "## 损失网络定义\n",
    "\n",
    "特征提取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GurC_h6yjlBw"
   },
   "outputs": [],
   "source": [
    "# 加载 `VGG19` 网络\n",
    "vgg19 = torchvision.models.vgg19(weights=torchvision.models.VGG19_Weights.DEFAULT).features.eval()\n",
    "vgg19 = vgg19[0:36]\n",
    "for param in vgg19.parameters():\n",
    "    param.requires_grad = False\n",
    "vgg19 = vgg19.to(device)\n",
    "\n",
    "# 计算Gama矩阵\n",
    "def compute_gama_matrix(x: torch.Tensor):\n",
    "    \"\"\"计算Gama矩阵\"\"\"\n",
    "    n, c, h, w = x.shape\n",
    "    x = x.view(n, c, h * w)\n",
    "    gama_matrix = torch.bmm(x, x.transpose(1, 2))\n",
    "    return gama_matrix\n",
    "\n",
    "# 提取特征\n",
    "def extract_feature(image_tensor: torch.Tensor):\n",
    "    \"\"\"提取特征\"\"\"\n",
    "    content_features, style_features = [], []\n",
    "    x = image_tensor\n",
    "    for i, layer in enumerate(vgg19):\n",
    "        x = layer(x)\n",
    "        if i in content_layers:\n",
    "            content_features.append(x)\n",
    "        if i in style_layers:\n",
    "            style_features.append(compute_gama_matrix(x)/ x.numel() * image_tensor.numel())\n",
    "    return content_features, style_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NlDbURY8jmqe"
   },
   "source": [
    "损失计算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3NCjoUSujp8V"
   },
   "outputs": [],
   "source": [
    "def compute_loss(generated_image: torch.Tensor, content_image: torch.Tensor, style_features) -> torch.Tensor:\n",
    "    \"\"\"计算损失\"\"\"\n",
    "    generated_content_features, generated_style_features = extract_feature(generated_image)\n",
    "    content_features, _ = extract_feature(content_image)\n",
    "\n",
    "    content_loss = 0\n",
    "    for i in range(len(content_features)):\n",
    "        content_loss += torch.nn.functional.mse_loss(generated_content_features[i], content_features[i])\n",
    "\n",
    "    style_loss = 0\n",
    "    for i in range(len(style_features)):\n",
    "        style_loss += torch.nn.functional.mse_loss(generated_style_features[i], style_features[i])\n",
    "\n",
    "    return content_loss * content_weight + style_loss * style_weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Upd43rwAjrkm"
   },
   "source": [
    "## 定义数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 20457,
     "status": "ok",
     "timestamp": 1736762014068,
     "user": {
      "displayName": "Carol",
      "userId": "14860603171832092381"
     },
     "user_tz": -480
    },
    "id": "o_aWA7jgjtuS",
    "outputId": "e5035fd3-7c89-4f7f-fc7f-e46572bc4713"
   },
   "outputs": [],
   "source": [
    "# modified from example code provided by ChatGPT\n",
    "import torch.utils\n",
    "\n",
    "\n",
    "class CocoDataset(CocoDetection):\n",
    "    \"\"\"Coco数据集加载及处理\"\"\"\n",
    "\n",
    "    def __init__(self, root: str, annFile: str, transform: transforms = None):\n",
    "        super().__init__(root, annFile)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index: int) -> torch.Tensor:\n",
    "        \"\"\"获取图像\"\"\"\n",
    "        img, _ = super().__getitem__(index)  # 忽略标注\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        return img\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "dataset = CocoDataset(root_dir, annFile, transform)\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S7Cs2TSkjvRq"
   },
   "source": [
    "## 定义网络及训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1480,
     "status": "ok",
     "timestamp": 1736762015546,
     "user": {
      "displayName": "Carol",
      "userId": "14860603171832092381"
     },
     "user_tz": -480
    },
    "id": "DxfV_ZRDjw-5",
    "outputId": "df70f25d-b0c2-46c4-ef32-588580f62d9a"
   },
   "outputs": [],
   "source": [
    "transformer = TransferNet().to(device)\n",
    "optimizer = torch.optim.AdamW(transformer.parameters(), lr=1e-3)\n",
    "style_image = Image.open(style_image_path).convert(\"RGB\")\n",
    "\n",
    "# 可视化检查\n",
    "# plt.figure(figsize=(10, 10), dpi=150)\n",
    "# plt.imshow(style_image)\n",
    "\n",
    "# 批量\n",
    "style_image = transform(style_image).unsqueeze(0).repeat(batch_size, 1, 1, 1).to(device)\n",
    "print(style_image.shape)\n",
    "\n",
    "_, style_features = extract_feature(style_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 2094157,
     "status": "error",
     "timestamp": 1736764109700,
     "user": {
      "displayName": "Carol",
      "userId": "14860603171832092381"
     },
     "user_tz": -480
    },
    "id": "CyDpBqR5j3U0",
    "outputId": "1c9022e1-eba7-4250-8af7-fc19b538de22"
   },
   "outputs": [],
   "source": [
    "best_model = None\n",
    "best_loss = float('inf')\n",
    "\n",
    "for epoch in range(1):\n",
    "    for i, data in enumerate(dataloader):\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        loss = compute_loss(transformer(data), data, style_features)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print(f\"Epoch: {epoch}, Batch: {i}, Loss: {loss.item()}\")\n",
    "        if loss < best_loss:\n",
    "            best_loss = loss\n",
    "            best_model = transformer.state_dict()\n",
    "            # save the best model\n",
    "            torch.save(best_model, \"/content/drive/MyDrive/best_model.pth\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMieaHsM+POac3q/dvnUj0I",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
