{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 快速风格迁移网络训练\n",
    "\n",
    "导入必要的包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torchvision\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import CocoDetection\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "配置参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 特征层\n",
    "content_layers = [22],\n",
    "style_layers = [1, 6, 11, 20, 29]\n",
    "\n",
    "content_weight = 1e3\n",
    "style_weight = 3e8\n",
    "\n",
    "root_dir = \"data/coco/val2017\"\n",
    "annFile = \"data/coco/annotations/instances_val2017.json\"\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "style_image_path = \"data/raw/style/starry_night.jpg\"\n",
    "\n",
    "batch_size = 8\n",
    "learning_rate = 1e-4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 生成模型定义\n",
    "\n",
    "降采样"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DownSample(nn.Module):\n",
    "    \"\"\"下采样层\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride):\n",
    "        super().__init__()\n",
    "        self.padding = nn.ReflectionPad2d(kernel_size // 2)\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size, stride)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"前向传播\"\"\"\n",
    "        return self.conv(self.padding(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "残差块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    \"\"\"残差块\"\"\"\n",
    "\n",
    "    def __init__(self, channels):\n",
    "        super().__init__()\n",
    "        self.padding1 = nn.ReflectionPad2d(1)\n",
    "        self.conv1 = nn.Conv2d(channels, channels, 3, 1)\n",
    "        self.in1 = nn.InstanceNorm2d(channels, affine=True)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.padding2 = nn.ReflectionPad2d(1)\n",
    "        self.conv2 = nn.Conv2d(channels, channels, 3, 1)\n",
    "        self.in2 = nn.InstanceNorm2d(channels, affine=True)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"前向传播\"\"\"\n",
    "        residual = x\n",
    "        out = self.relu(self.in1(self.conv1(self.padding1(x))))\n",
    "        out = self.in2(self.conv2(self.padding2(out)))\n",
    "        out = out + residual\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "升采样"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UpSample(nn.Module):\n",
    "    \"\"\"上采样层\"\"\"\n",
    "\n",
    "    # pylint: disable=too-many-arguments, too-many-positional-arguments\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride, upsample=None):\n",
    "        super().__init__()\n",
    "        self.upsample = upsample\n",
    "        self.padding = nn.ReflectionPad2d(kernel_size // 2)\n",
    "        self.conv2d = nn.Conv2d(in_channels, out_channels, kernel_size, stride)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"前向传播\"\"\"\n",
    "        x_in = x\n",
    "        if self.upsample:\n",
    "            x_in = torch.nn.functional.interpolate(\n",
    "                x_in, mode=\"nearest\", scale_factor=self.upsample\n",
    "            )\n",
    "        return self.conv2d(self.padding(x_in))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "模型定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransferNet(nn.Module):\n",
    "    \"\"\"风格迁移网络\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.downsample1 = DownSample(3, 32, 9, 1)\n",
    "        self.in1 = nn.InstanceNorm2d(32, affine=True)\n",
    "        self.downsample2 = DownSample(32, 64, 3, 2)\n",
    "        self.in2 = nn.InstanceNorm2d(64, affine=True)\n",
    "        self.downsample3 = DownSample(64, 128, 3, 2)\n",
    "        self.in3 = nn.InstanceNorm2d(128, affine=True)\n",
    "        self.residual1 = ResidualBlock(128)\n",
    "        self.residual2 = ResidualBlock(128)\n",
    "        self.residual3 = ResidualBlock(128)\n",
    "        self.residual4 = ResidualBlock(128)\n",
    "        self.residual5 = ResidualBlock(128)\n",
    "        self.upsample1 = UpSample(128, 64, 3, 1, 2)\n",
    "        self.in4 = nn.InstanceNorm2d(64, affine=True)\n",
    "        self.upsample2 = UpSample(64, 32, 3, 1, 2)\n",
    "        self.in5 = nn.InstanceNorm2d(32, affine=True)\n",
    "        self.upsample3 = DownSample(32, 3, 9, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"前向传播\"\"\"\n",
    "        out = self.relu(self.in1(self.downsample1(x)))\n",
    "        out = self.relu(self.in2(self.downsample2(out)))\n",
    "        out = self.relu(self.in3(self.downsample3(out)))\n",
    "        out = self.residual1(out)\n",
    "        out = self.residual2(out)\n",
    "        out = self.residual3(out)\n",
    "        out = self.residual4(out)\n",
    "        out = self.residual5(out)\n",
    "        out = self.relu(self.in4(self.upsample1(out)))\n",
    "        out = self.relu(self.in5(self.upsample2(out)))\n",
    "        out = self.upsample3(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 损失网络定义\n",
    "\n",
    "特征提取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载 `VGG19` 网络\n",
    "vgg19 = torchvision.models.vgg19(weights=torchvision.models.VGG19_Weights.DEFAULT).features.eval()\n",
    "vgg19 = vgg19[0:36]\n",
    "for param in vgg19.parameters():\n",
    "    param.requires_grad = False\n",
    "vgg19 = vgg19.to(device)\n",
    "\n",
    "# 计算Gama矩阵\n",
    "def compute_gama_matrix(x: torch.Tensor):\n",
    "    \"\"\"计算Gama矩阵\"\"\"\n",
    "    n, c, h, w = x.shape\n",
    "    x = x.view(n, c, h * w)\n",
    "    gama_matrix = torch.bmm(x, x.transpose(1, 2))\n",
    "    return gama_matrix\n",
    "\n",
    "# 提取特征\n",
    "def extract_feature(image_tensor: torch.Tensor):\n",
    "    \"\"\"提取特征\"\"\"\n",
    "    content_features, style_features = [], []\n",
    "    x = image_tensor\n",
    "    for i, layer in enumerate(vgg19):\n",
    "        x = layer(x)\n",
    "        if i in content_layers:\n",
    "            content_features.append(x)\n",
    "        if i in style_layers:\n",
    "            style_features.append(compute_gama_matrix(x)/ x.numel())\n",
    "    return content_features, style_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "损失计算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss(generated_image: torch.Tensor, content_image: torch.Tensor, style_features) -> torch.Tensor:\n",
    "    \"\"\"计算损失\"\"\"\n",
    "    generated_content_features, generated_style_features = extract_feature(generated_image)\n",
    "    content_features, _ = extract_feature(content_image)\n",
    "\n",
    "    content_loss = 0\n",
    "    for i in range(len(content_features)):\n",
    "        content_loss += torch.nn.functional.mse_loss(generated_content_features[i], content_features[i])\n",
    "\n",
    "    style_loss = 0\n",
    "    for i in range(len(style_features)):\n",
    "        style_loss += torch.nn.functional.mse_loss(generated_style_features[i], style_features[i])\n",
    "\n",
    "    return content_loss * content_weight + style_loss * style_weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modified from example code provided by ChatGPT\n",
    "import torch.utils\n",
    "\n",
    "\n",
    "class CocoDataset(CocoDetection):\n",
    "    \"\"\"Coco数据集加载及处理\"\"\"\n",
    "\n",
    "    def __init__(self, root: str, annFile: str, transform: transforms = None):\n",
    "        super().__init__(root, annFile)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index: int) -> torch.Tensor:\n",
    "        \"\"\"获取图像\"\"\"\n",
    "        img, _ = super().__getitem__(index)  # 忽略标注\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        return img\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "dataset = CocoDataset(root_dir, annFile, transform)\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义网络及训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = TransferNet().to(device)\n",
    "optimizer = torch.optim.AdamW(transformer.parameters(), lr=1e-3)\n",
    "style_image = Image.open(style_image_path).convert(\"RGB\")\n",
    "\n",
    "# 可视化检查\n",
    "plt.figure(figsize=(10, 10), dpi=150)\n",
    "plt.imshow(style_image)\n",
    "\n",
    "# 批量\n",
    "style_image = transform(style_image).unsqueeze(0).repeat(batch_size, 1, 1, 1).to(device)\n",
    "print(style_image.shape)\n",
    "\n",
    "_, style_features = extract_feature(style_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = None\n",
    "best_loss = float('inf')\n",
    "\n",
    "for epoch in range(10):\n",
    "    for i, data in enumerate(dataloader):\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        loss = compute_loss(transformer(data), data, style_features)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print(f\"Epoch: {epoch}, Batch: {i}, Loss: {loss.item()}\")\n",
    "        if loss < best_loss:\n",
    "            best_loss = loss\n",
    "            best_model = transformer.state_dict()\n",
    "            # save the best model\n",
    "            torch.save(best_model, \"experiments/models/best_model.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "style_transfer",
   "language": "python",
   "name": "style_transfer"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
